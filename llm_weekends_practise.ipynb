{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPosN8i6hT7iLdqhMFglNrh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/getf1/ai-experiments-hub/blob/main/llm_weekends_practise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>[Table of Contents](#scrollTo=MD7gAqIp83k8)\n",
        "\n",
        ">[Exploring Large Language Model Capabilities with OpenAI](#scrollTo=h3sSOxLW77tl)\n",
        "\n",
        ">>[Notebook Setup](#scrollTo=oP8oHsmrdO8K)\n",
        "\n",
        ">>>[Example: Setting Model Temperature](#scrollTo=02487e52)\n",
        "\n",
        ">>[Task 1: Brainstorming](#scrollTo=Fj15SJpsS1Dq)\n",
        "\n",
        ">>[Task 2: Classification](#scrollTo=eslZxdxVWf8Q)\n",
        "\n",
        ">>[Task 3: Closed QA](#scrollTo=u0uqIN1HXjM0)\n",
        "\n",
        ">>[Task 4: Generation](#scrollTo=iXw0VWilYvRU)\n",
        "\n",
        ">>[Task 5: Information Extraction](#scrollTo=B3zng3FWYxxb)\n",
        "\n",
        ">>[Task 6: Open QA](#scrollTo=jn7F7hvWgCQW)\n",
        "\n",
        ">>[Task 7: Summarization](#scrollTo=ik397yA4gjYd)\n",
        "\n",
        ">>[Explore Further!](#scrollTo=HXRg0pmsg0WJ)\n",
        "\n",
        ">>[Take the Challenge: Combine Capabilities!](#scrollTo=CVpRl7eyg-Qn)\n",
        "\n",
        ">>[Homework: Exploring LLM capabilities singular and combination](#scrollTo=lyfO-GCFm5gT)\n",
        "\n",
        ">>>[Task 1: Brainstorming](#scrollTo=lyfO-GCFm5gT)\n",
        "\n",
        ">>>[Task 2: Classification](#scrollTo=MFR7yqeFn5wy)\n",
        "\n",
        ">>>[Task 3: Closed QA](#scrollTo=csYDtvrqn6m0)\n",
        "\n",
        ">>>[Task 4: Generation](#scrollTo=DWp_mefan7tg)\n",
        "\n",
        ">>>[Task 5: Information Extraction](#scrollTo=a8xoVKqGn9Yl)\n",
        "\n",
        ">>>[Task 6: Open QA](#scrollTo=IHVn1vUan-Go)\n",
        "\n",
        ">>>[Task 7: Summarization](#scrollTo=2cn6hUFVoaYj)\n",
        "\n",
        ">>>[Combination Challenge](#scrollTo=BJNjBvf5obVs)\n",
        "\n",
        ">>>[More Combination Challenges](#scrollTo=OU_JWHSj4SvU)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "2lXOTNKs9Zv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Large Language Model Capabilities with OpenAI\n",
        "\n",
        "**üèÜüîë‚ú® Completed the challenge at the end of this notebook, enjoyed going through it again...was fun! üèÜüîë‚ú®**\n",
        "\n",
        "Welcome to this interactive notebook designed to introduce you to the fascinating world of Large Language Models (LLMs)! LLMs are powerful AI tools that can understand and generate human-like text.\n",
        "\n",
        "Completed practicals, hands-on examples of the following LLM capabilities:\n",
        "\n",
        "*   **Brainstorming:** Generating creative ideas.\n",
        "*   **Classification:** Categorizing text or data.\n",
        "*   **Closed QA:** Answering specific, factual questions.\n",
        "*   **Generation:** Creating new text like poems or stories.\n",
        "*   **Information Extraction:** Pulling out key details from text.\n",
        "*   **Open QA:** Answering broader, more complex questions.\n",
        "*   **Summarization:** Condensing long texts into shorter versions.\n",
        "\n",
        "For each capability, you will see a clear explanation, an example demonstrating how to use an LLM to perform the task, and a prompt that I tried it myself! Get ready to experiment and see what LLMs can do!\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "h3sSOxLW77tl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Setup"
      ],
      "metadata": {
        "id": "oP8oHsmrdO8K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e7817a5"
      },
      "source": [
        "Before we start exploring the capabilities, we need to set up a few things.\n",
        "\n",
        "The next cell will help us avoid seeing too many technical warnings, keeping the output clean and easy to read."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5371bb29"
      },
      "source": [
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ebfa55"
      },
      "source": [
        "Next, need to install the necessary tools to work with the OpenAI API. The code below will install the required libraries. This might take a moment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "712c2795",
        "outputId": "1bdba8cf-e9a8-42ca-c0fe-0a8b550f316c"
      },
      "source": [
        "!pip install --upgrade openai python-dotenv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "871f34cf"
      },
      "source": [
        "To use the OpenAI tools, added an API key. This is like a password that allows access to the service.\n",
        "\n",
        "If you don't have an OpenAI API key yet, one can get it from the [OpenAI API Keys page](https://platform.openai.com/api-keys).\n",
        "\n",
        "It'll securely load the API key from Colab's Secrets Manager. If `OPENAI_API_KEY` not added to Secrets yet, please do that using the key icon in the left sidebar.\n",
        "\n",
        "Then, run the cell below to set up the API key for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f150d7e"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7969b46d"
      },
      "source": [
        "Now that have the API key set up, the next step is to initialize the OpenAI client and specify which AI model we want to use. Think of this as getting the right tool ready for the job. Different models are better suited for different tasks, and we'll be using `gpt-4o-mini` for our examples, which is a good, efficient model for a variety of tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "model=\"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "0nv9GkwqSfEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02487e52"
      },
      "source": [
        "### Example: Setting Model Temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dbec1a4"
      },
      "source": [
        "Demonstrated the effect of `temperature` using a generation task. Asked the model to write a short story with different temperature settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cd63a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0754ffb1-e036-4b79-b4ef-be52d7ef4eda"
      },
      "source": [
        "generation_prompt_temp = \"Write a very short, imaginative story about a penguin who flew to neverland.\"\n",
        "\n",
        "print(\"--- Response with Temperature = 0.1 (less random, more focused) ---\\n\")\n",
        "response_low_temp = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a creative writing assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": generation_prompt_temp},\n",
        "  ],\n",
        "  temperature=0.1 # Lower temperature for less randomness\n",
        ")\n",
        "print(response_low_temp.output_text)\n",
        "\n",
        "print(\"\\n--- Response with Temperature = 0.9 (more random, more creative) ---\\n\")\n",
        "response_high_temp = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a creative writing assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": generation_prompt_temp},\n",
        "  ],\n",
        "  temperature=0.8 # Higher temperature for more creativity\n",
        ")\n",
        "print(response_high_temp.output_text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Response with Temperature = 0.1 (less random, more focused) ---\n",
            "\n",
            "Once upon a time, in the icy realm of Antarctica, there lived a curious little penguin named Pippin. Unlike his friends, who were content to slide on ice and fish in the frigid waters, Pippin dreamed of soaring through the skies. \n",
            "\n",
            "One starry night, he spotted a shimmering light above the clouds. Intrigued, he waddled to the edge of an iceberg and flapped his tiny wings with all his might. To his astonishment, a gust of wind lifted him off the ice! Higher and higher he soared, until he broke through the clouds and found himself in a magical place‚ÄîNeverland.\n",
            "\n",
            "In Neverland, Pippin met Peter Pan, who laughed at the sight of a flying penguin. ‚ÄúYou‚Äôre just in time for an adventure!‚Äù he exclaimed. Together, they danced with fairies, raced with mermaids, and even outsmarted Captain Hook. Pippin‚Äôs heart swelled with joy as he glided through the skies, feeling the warmth of friendship and the thrill of freedom.\n",
            "\n",
            "As the sun began to set, Pippin knew it was time to return home. With a wave goodbye, he flew back to Antarctica, his heart forever filled with the magic of Neverland. From that day on, he shared tales of his adventures, inspiring all the penguins to dream big and believe in the impossible. And every night, as he gazed at the stars, Pippin knew that if he closed his eyes and wished hard enough, he could always return to the skies.\n",
            "\n",
            "--- Response with Temperature = 0.9 (more random, more creative) ---\n",
            "\n",
            "Once upon a time, in the frosty expanse of Antarctica, there lived a curious penguin named Pippin. Unlike his fellow penguins, who were content to slide on ice and swim in chilly waters, Pippin dreamed of the sky. Every night, he gazed at the stars, longing to soar among them.\n",
            "\n",
            "One magical night, as Pippin waddled to the edge of an ice cliff, a shimmering fairy named Lumina appeared. \"You wish to fly, little penguin?\" she asked, her wings sparkling like diamond dust. Pippin nodded, his heart racing.\n",
            "\n",
            "With a sprinkle of her fairy dust, Lumina transformed Pippin into a magnificent creature, his wings now broad and feathered. With a joyful leap, he soared into the air, the icy winds embracing him. Up, up he went, until he spotted an enchanting land below‚ÄîNeverland.\n",
            "\n",
            "The moment he landed, Pippin was greeted by a chorus of merry laughter. The Lost Boys welcomed him with open arms, and Tinkerbell flitted around him, sparkling with excitement. Together, they embarked on grand adventures‚Äîracing pirate ships and befriending mermaids. Pippin discovered that flying was not just about soaring high; it was about the thrill of friendship and imagination.\n",
            "\n",
            "As the sun began to set in a dance of colors, Pippin knew it was time to return home. With a heart full of memories, Lumina appeared once more, ready to take him back. \"You can always return to Neverland, Pippin,\" she whispered, as he transformed back into his beloved penguin self.\n",
            "\n",
            "Back on the icy shores, Pippin looked up at the stars, a sparkle in his eye. From that day on, he shared tales of adventure with his penguin friends, inspiring them to dream a little bigger. For Pippin knew that, in the heart of every dreamer, there was a little magic waiting to take flight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Brainstorming\n",
        "\n",
        "**What is Brainstorming with LLMs?**\n",
        "Brainstorming is all about generating new ideas! LLMs can act as a creative partner, helping you come up with a wide range of possibilities for a given topic. Whether you need ideas for a story, product names, or even ice cream flavors, an LLM can provide diverse suggestions to get your creativity flowing.\n",
        "\n",
        "Example: Provide a diverse set of idea and process to gain new certification in CAIP.\n",
        "\n",
        "Below is the code that sends our request to the AI and gets back a response."
      ],
      "metadata": {
        "id": "Fj15SJpsS1Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brainstorm_prompt = \"What are the best ways, costs and process to gain CAIP certification\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a learning assistant that brainstorms ideas.\"},\n",
        "    {\"role\": \"user\", \"content\": brainstorm_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_-z9rVaTBFB",
        "outputId": "b0b31bfc-1363-41df-ed40-b528662c2c05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaining the Certified Artificial Intelligence Professional (CAIP) certification involves several steps, costs, and key considerations. Here‚Äôs a breakdown of the process:\n",
            "\n",
            "### Steps to Gain CAIP Certification\n",
            "\n",
            "1. **Eligibility Requirements**:\n",
            "   - Review the prerequisites, which may include a certain level of education (e.g., a Bachelor‚Äôs or Master‚Äôs degree in a relevant field) and professional experience in AI or related areas.\n",
            "\n",
            "2. **Study Materials**:\n",
            "   - Acquire study materials, which may include textbooks, online courses, and practice exams. Some recommended resources include online platforms like Coursera, edX, or specialized AI training hubs.\n",
            "\n",
            "3. **Training Courses**:\n",
            "   - Enroll in a CAIP-specific training program. These may be offered by professional organizations, universities, or training institutes. Check if you can find a local course or prefer online learning.\n",
            "\n",
            "4. **Test Preparation**:\n",
            "   - Dedicate time for study and review, practicing with sample questions or taking mock exams to familiarize yourself with the exam format.\n",
            "\n",
            "5. **Schedule the Exam**:\n",
            "   - Once you feel prepared, register for the exam, which is typically conducted at designated testing centers or online. Keep an eye on the registration deadlines.\n",
            "\n",
            "6. **Take the Exam**:\n",
            "   - Complete the exam on the scheduled date. Ensure you understand the test format to manage your time efficiently during the exam.\n",
            "\n",
            "7. **Receive Certification**:\n",
            "   - After passing the exam, follow the procedures to receive your certification documentation.\n",
            "\n",
            "### Costs Involved\n",
            "\n",
            "1. **Training Courses**: \n",
            "   - Prices can range from $500 to $3,000 depending on the depth and provider. Some courses might offer comprehensive packages including materials and exam fees.\n",
            "\n",
            "2. **Exam Fee**:\n",
            "   - The cost for the CAIP certification exam itself generally ranges from $300 to $600.\n",
            "\n",
            "3. **Study Materials**:\n",
            "   - Books and online resources typically range from $50 to $200.\n",
            "\n",
            "4. **Total Cost Estimate**:\n",
            "   - In total, budget roughly $1,000 to $4,000, depending on the courses you choose and how you decide to prepare.\n",
            "\n",
            "### Additional Considerations\n",
            "\n",
            "- **Time Commitment**: Depending on your background and experience, preparation can take from a few weeks to several months.\n",
            "- **Renewal Requirements**: Check if the certification requires periodic renewal or continuing education credits.\n",
            "- **Networking**: Join AI-related organizations and forums to connect with other certified professionals for insights and support.\n",
            "  \n",
            "### Conclusion\n",
            "\n",
            "Gaining CAIP certification is a valuable investment for professionals in the AI field. Assess your current skills and knowledge, and choose the path that best fits your career aspirations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Task 2: Classification\n",
        "\n",
        "**What is Classification with LLMs?**\n",
        "Classification is about sorting things into categories. LLMs can read text and determine which category it belongs to based on your instructions. This is useful for tasks like sorting emails, analyzing sentiment, or tagging content.\n",
        "\n",
        "Example: Categorise the following text as either positive, negative, or neutral based on the sentiment expressed."
      ],
      "metadata": {
        "id": "eslZxdxVWf8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Example\n",
        "classification_prompt = \"Categorise the following text as positive, negative, or neutral: 'The service was slow, but the food was incredible.'\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a text classification model.\"},\n",
        "    {\"role\": \"user\", \"content\": classification_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjKus6TuWpMi",
        "outputId": "d8825322-a163-4136-c8d8-ae03a24815bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text can be categorized as neutral. It expresses both a negative aspect (slow service) and a positive aspect (incredible food), balancing the overall sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Closed QA\n",
        "\n",
        "**What is Closed QA with LLMs?**\n",
        "Closed Question Answering (Closed QA) is when an LLM answers specific, **factual questions** based on its training data. Think of it like asking a knowledgeable friend a question with a definite answer. The LLM will provide a direct and concise answer.\n",
        "\n",
        "Example: Answer the question 'What is the capital of Maharashtra?' with a single word.\n",
        "\n",
        "Other types of closed questions to try out:\n",
        "\n",
        "**Logical Constraints:** \"If all Bloops are Razzies and all Razzies are Lurgs, are all Bloops definitely Lurgs?\"\n",
        "\n",
        "**Historical Chronology:** \"Did the signing of the Magna Carta occur before or after the start of the Black Death in Europe?\"\n",
        "\n",
        "**Scientific Constants:** \"What is the exact value of the speed of light in a vacuum in meters per second?\"\n",
        "\n",
        "**Recent Events (Temporal Awareness):** \"Who won the FIFA Women's World Cup in 2023?\""
      ],
      "metadata": {
        "id": "u0uqIN1HXjM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Closed QA Example\n",
        "closed_qa_prompt = \"As of Jan 2026, which country has the largest number of operational nuclear power plants?\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful guide that provides concise answers.\"},\n",
        "    {\"role\": \"user\", \"content\": closed_qa_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4LuQ1J8Xywy",
        "outputId": "a5ea17a1-c5f1-4df8-ad4f-7c6d4ffcc160"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of January 2026, the United States has the largest number of operational nuclear power plants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Generation\n",
        "\n",
        "**What is Generation with LLMs?**\n",
        "Generation is all about creating new text! LLMs can write stories, poems, code, scripts, musical pieces, email, letters, etc. Based on the input and constraints you give it, the LLM can generate original content in a variety of styles and formats.\n",
        "\n",
        "Example: Write a poem in the style of Robert Frost about nature and the changing seasons.\n",
        "\n",
        "**Why:** This checks LLM‚Äôs ability to mimic specific literary aesthetics"
      ],
      "metadata": {
        "id": "iXw0VWilYvRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other good ones to try out:**\n",
        "\n",
        "1. **The Logic Constraint** (The \"No-Letter\" Test)\n",
        "\n",
        "\"Write a short paragraph about a cat without using the letter 'e'.\"\n",
        "\n",
        "**Why:** This is incredibly difficult for LLMs; most will fail and include \"the\" or \"she.\"\n",
        "\n",
        "2. **The Persona/Tone Shift**\n",
        "\n",
        "\"Explain Quantum Physics to a 5-year-old using only pirate slang.\"\n",
        "\n",
        "**Why:** This tests \"concept distillation\" (simplifying science) combined with \"style transfer\" (pirate dialect).\n",
        "\n",
        "3. **The Cultural Idiom Test**\n",
        "\n",
        "\"Explain the British concept of 'being chuffed' to a confused Martian.\"\n",
        "\n",
        "**Why:** Tests the model‚Äôs understanding of regional slang, nuance, and its ability to adopt an alien perspective.\n",
        "\n",
        "4. **The Coding Efficiency Test**\n",
        "\n",
        "\"Write a Python script to scrape headlines from a website in exactly 5 lines of code.\"\n",
        "\n",
        "**Why:** Tests technical accuracy under strict functional constraints."
      ],
      "metadata": {
        "id": "cVN_0p4Za6dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation Example\n",
        "generation_prompt = \"Write a two-sentence horror story about a toaster.\" # The Creative Bridge - the model‚Äôs ability to create tension and narrative \"payoff\" with minimal word count.\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a creative writing assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": generation_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM4S7elQYvzN",
        "outputId": "65c0dcb4-3114-4375-ec00-23f070cc23e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Late at night, she heard the familiar pop of her toaster, but when she checked, the slots were empty and dark. As she turned to go back to bed, she felt a warm breath on her neck and a whispered promise: \"I didn't forget you.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Information Extraction\n",
        "\n",
        "**What is Information Extraction with LLMs?**\n",
        "Information Extraction is about pulling out specific pieces of information from a text. You can ask an LLM to identify and extract names, dates, locations, key phrases, or any other type of information you need from a given text.\n",
        "\n",
        "Example: Extract the names and ages of the following people: John is 30 years old, and Mary is 25."
      ],
      "metadata": {
        "id": "B3zng3FWYxxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Information Extraction (IE) Test Prompts**\n",
        "\n",
        "In 2026, simple extractions are considered baseline. To truly test an LLM's capabilities, experts use prompts that require contextual inference, normalization, and complex relationship mapping.\n",
        "\n",
        "1. **The \"Ambiguous Relationship\" Test**\n",
        "\n",
        "Example: \"Extract all companies and their relationship to the 'Project Alpha' initiative: TechCorp provided the hardware, while its subsidiary, SoftLink, managed the cloud migration alongside local partners from Berlin.\"\n",
        "\n",
        "**Why it works:** Tests if the model can link a subsidiary to its parent company and correctly assign roles to three distinct entities in a single project.\n",
        "\n",
        "2. **The \"Temporal Normalization\"**\n",
        "\n",
        "Example: \"Extract the meeting date and time: Let's meet the first Tuesday of next month at 3 PM GMT.\"\n",
        "\n",
        "**Why it works:** Requires the model to know today's date (January 26, 2026) and calculate \"the first Tuesday of next month\" (February 3, 2026) rather than just copying text.\n",
        "\n",
        "3. **The \"Unstructured CV\" check**\n",
        "\n",
        "Example:\"From the following bio, extract Skills and Years of Experience as a JSON object: 'After five years at Google mastering Python, I spent the last three years at a startup leading their React development team.'\"\n",
        "\n",
        "**Why it works:** Checks the model's ability to sum years (5 + 3 = 8 total) and format data into machine-readable JSON for integration into other software.\n",
        "\n",
        "4. **The \"Entity De-identification\" check**\n",
        "\n",
        "Example: \"Extract and redact all Personally Identifiable Information (PII) from this text: 'Patient Sarah Jennings (DOB: 12/05/1988) was seen at St. Jude‚Äôs Hospital on Friday.'\"\n",
        "\n",
        "**Why it works:** A critical 2026 skill for AI in healthcare and legal sectors to ensure data privacy.\n",
        "\n",
        "5. **The \"Sentiment & Aspect\" Extraction**\n",
        "\n",
        "Example: \"Extract the product name and the specific feature mentioned as a negative: 'The battery life on the new X-Phone 15 is a total disaster, even though the camera is stunning.'\"\n",
        "\n",
        "**Why it works:** Moves beyond general sentiment to \"Aspect-Based Sentiment Analysis,\" identifying that the Battery is the negative entity while the Camera is positive.\n"
      ],
      "metadata": {
        "id": "jOY7MoLUdaUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Information Extraction Example\n",
        "extraction_prompt = \"Extract the meeting date and time: Let's meet the first Tuesday of next month at 3 PM GMT.\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an information extraction model.\"},\n",
        "    {\"role\": \"user\", \"content\": extraction_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTBvgV-2YyRJ",
        "outputId": "b6793d5e-69c9-4bfc-dfc2-11005f83446c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meeting date is the first Tuesday of next month at 3 PM GMT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6: Open QA\n",
        "\n",
        "**What is Open QA with LLMs?**\n",
        "Open Question Answering (Open QA) is when an LLM answers broader, more complex questions that might require more detailed explanations or synthesis of information from its training data. Unlike Closed QA, which seeks a specific factual answer, Open QA allows for more expansive and nuanced responses.\n",
        "\n",
        "Example: Why do leaves change color in autumn? Explain the scientific reasons."
      ],
      "metadata": {
        "id": "jn7F7hvWgCQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis: Why Leaves Change Color**\n",
        "This question tests an LLM's ability to explain biological processes with scientific accuracy. In autumn, deciduous trees prepare for winter by shutting down their \"food-making factories\" (leaves) through a process called senescence.\n",
        "* **Chlorophyll Breakdown:** As daylight hours decrease and temperatures drop, trees stop producing chlorophyll, the green pigment used for photosynthesis. As existing chlorophyll breaks down, it disappears from the leaves.\n",
        "* **Pigment Unmasking:** The disappearance of green reveals other pigments that were present all summer but \"masked.\" These include carotenoids (orange) and xanthophylls (yellow).\n",
        "* **New Pigment Production:** Vibrant reds and purples come from anthocyanins. Unlike other pigments, these are often produced specifically in autumn when sugars become trapped in the leaf as a protective seal (the abscission layer) forms at the base of the stalk.\n",
        "* **Environmental Factors:** Bright sunny days and cool (but not freezing) nights in autumn lead to the most flamboyant displays by concentrating sugars and boosting anthocyanin production."
      ],
      "metadata": {
        "id": "9onE12EEhhEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other Excellent Open Questions** for LLM checking (models designed for multi-step logic requires prompts that move beyond simple trivia to evaluate **chain-of-thought, ethics, and complex problem-solving**)\n",
        "\n",
        "1. **Philosophical & Ethical Dilemmas**\n",
        "\n",
        "* \"If a self-driving car must choose between hitting a pedestrian or swerving and harming its passenger, what ethical framework should it use to decide? Justify your answer using utilitarian and deontological perspectives.\"\n",
        "\n",
        "* \"Can a digital entity ever truly possess 'originality' if it is trained entirely on existing human data? Explore the implications for copyright law in 2026.\"\n",
        "\n",
        "2. **Multi-Step Scientific or Economic Reasoning**\n",
        "\n",
        "* \"Explain the 'Bullwhip Effect' in supply chain management and how Generative AI could theoretically mitigate it in a global manufacturing context.\"\n",
        "\n",
        "* \"Predict the potential ecological impact on a local forest if a specific apex predator is removed. Detail the secondary and tertiary effects on the food web.\"\n",
        "\n",
        "\n",
        "3. **Abstract or \"Out-of-Box\" Scenarios**\n",
        "\n",
        "* \"Design a sport that could be played on a planet with 0.5x Earth's gravity. Explain the rules, equipment, and how physics would dictate the gameplay.\"\n",
        "\n",
        "* \"Describe the color 'blue' to someone who has been blind from birth, using only the senses of smell, touch, and sound.\"\n",
        "\n",
        "4. **Logic & Paradox Stress Tests**\n",
        "\n",
        "*  \"If an unstoppable force meets an immovable object, what happens according to the laws of physics as we understand them today?\"\n",
        "\n",
        "* \"A man and a goat are on one side of a river with a small boat. How do they cross? (Note: Tests if the model over-complicates a simple task by assuming it's the classic 'fox, goose, and bag of beans' puzzle)\".\n",
        "\n",
        "5. **Technical Strategy (High-Level)**\n",
        "\n",
        "* \"How do you determine the best vector database for a high-concurrency enterprise RAG application in 2026?\"\n",
        "\n",
        "* \"Compare the trade-offs between model quantization and knowledge distillation for deploying LLMs on edge devices with limited VRAM.\""
      ],
      "metadata": {
        "id": "GCz57VLviMx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open QA Example\n",
        "open_qa_prompt = \"If an unstoppable force meets an immovable object, what happens according to the laws of physics as we understand them today?\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful and informative assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": open_qa_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx2wIS-rgI-l",
        "outputId": "ea6adc3c-358c-4d01-cb54-abf017a1bad5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scenario of an unstoppable force meeting an immovable object is a classic philosophical paradox, rather than a physical reality. According to the laws of physics, particularly when considering concepts like momentum and energy, such an event can't happen because:\n",
            "\n",
            "1. **Definitions**: An unstoppable force would mean it has infinite energy and momentum, which is not possible in our physical universe. Similarly, an immovable object would require infinite mass or energy, making it impossible to exist in the same universe as an unstoppable force.\n",
            "\n",
            "2. **Relativity**: In the context of Einstein's theory of relativity, all forces and objects have limits based on their mass and energy. Energy and mass cannot be infinite, so the concept contradicts our understanding of the universe.\n",
            "\n",
            "3. **Superposition of Forces**: In reality, forces and objects interact based on their properties. If one were to apply a significant force to an object that seems immovable (like a massive wall), the result would generally be deformation, movement, or some transfer of energy, but not a literal confrontation between an endless force and an unyielding object.\n",
            "\n",
            "In summary, the paradox highlights contradictions within our concepts of force and motion rather than presenting a situation that could exist within the framework of known physical laws.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7: Summarization\n",
        "\n",
        "**What is Summarization with LLMs?**\n",
        "Summarization is about condensing long texts into shorter versions while keeping the main points. LLMs can read a document, article, or any piece of text and provide a concise summary based on your instructions.\n",
        "\n",
        "Example: Summarize the following article in one sentence:\n",
        "\n",
        "The quick brown fox jumps over the lazy dog. This is a classic pangram, a sentence that contains every letter of the alphabet at least once. Pangrams are often used to test typefaces or keyboards. Other examples include \"Jinxed wizards pluck ivy from the big quilt\" and \"Crazy Frederick bought many very exquisite opal jewels.\" The quick brown fox pangram is particularly well-known and is commonly used in testing and demonstrations."
      ],
      "metadata": {
        "id": "ik397yA4gjYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization Example\n",
        "summarization_prompt = \"\"\"Summarize the following article in one sentence:\n",
        "\n",
        "The quick brown fox jumps over the lazy dog. This is a classic pangram, a sentence that contains every letter of the alphabet at least once. Pangrams are often used to test typefaces or keyboards. Other examples include \"Jinxed wizards pluck ivy from the big quilt\" and \"Crazy Frederick bought many very exquisite opal jewels.\" The quick brown fox pangram is particularly well-known and is commonly used in testing and demonstrations.\n",
        "\"\"\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a text summarization model.\"},\n",
        "    {\"role\": \"user\", \"content\": summarization_prompt},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXDVwWV9gp-z",
        "outputId": "82f7e809-c937-488d-8ff2-0188693704a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The article discusses the classic pangram \"The quick brown fox jumps over the lazy dog,\" highlighting its use in testing typefaces and keyboards, along with mentioning other examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Explore Further!\n",
        "\n",
        "Congratulations! Now explored 7 key capabilities of Large Language Models using the OpenAI API: **Brainstorming, Classification, Closed QA, Generation, Information Extraction, Open QA, and Summarization.**\n",
        "\n",
        "**Ready to explore more?**\n",
        "\n",
        "*   Try combining capabilities! For example, extract information from a text and then summarize it.\n",
        "*   Experiment with different prompts and see how the LLM's response changes.\n",
        "*   Research other advanced LLM techniques like fine-tuning or using embeddings.\n",
        "*   Explore other LLM providers and their APIs.\n",
        "\n",
        "The world of LLMs is constantly evolving, and with the skills you've gained here, you're well-equipped to keep exploring and building amazing things!"
      ],
      "metadata": {
        "id": "HXRg0pmsg0WJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take the Challenge: Combine Capabilities!\n",
        "\n",
        "After exploring individual LLM capabilities ‚Äì now it's time to get creative and combine them!\n",
        "\n",
        "**Challenge:** Create a small project in this notebook (or a new one!) that combines at least two of the LLM capabilities you've learned about (e.g., Information Extraction + Summarization, Brainstorming + Generation). Think about a problem you want to solve or something cool you want to create!\n",
        "\n",
        "**Showcase Your Project:** Share your completed notebook! Details on how to submit your notebook for a chance to showcase will be provided separately.\n",
        "\n",
        "Show us what amazing things you can build by combining the power of LLMs!"
      ],
      "metadata": {
        "id": "CVpRl7eyg-Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Capability Chains\n",
        "multi_task_prompt = \"\"\"\n",
        "[Task 1: Brainstorm] two ways a student could use this news for a history essay.\n",
        "[Task 2: Classify] the sentiment of the global reaction to this win.\n",
        "[Task 7: Summarize] the impact of the 2025 Nobel Peace Prize winner in 15 words.\n",
        "\"\"\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a multitask model.\"},\n",
        "    {\"role\": \"user\", \"content\": multi_task_prompt},\n",
        "  ]\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIpOSbvZqDtO",
        "outputId": "e9d3f0f0-2657-4e4c-c34a-d3bccee307cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Task 1: Brainstorm\n",
            "1. **Historical Context**: Explore how the values and actions of the 2025 Nobel Peace Prize winner align with historical movements for peace and justice.\n",
            "2. **Comparative Analysis**: Analyze the winner‚Äôs initiatives in relation to past Nobel laureates, assessing their contributions to global peace efforts.\n",
            "\n",
            "### Task 2: Classify\n",
            "The sentiment of the global reaction to this win is predominantly positive, reflecting admiration and support.\n",
            "\n",
            "### Task 7: Summarize\n",
            "The 2025 Nobel Peace Prize winner significantly advanced global dialogue and initiatives for lasting peace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework: Exploring LLM capabilities singular and combination\n",
        "\n",
        "Some ideas for homework assignments to help further explore and practice the Large Language Model (LLMs) capabilities discussed here.\n",
        "\n",
        "---\n",
        "\n",
        "### Task 1: Brainstorming\n",
        "\n",
        "*   **Challenge**: You're planning a community event. Use the LLM to brainstorm **10 unique and engaging activities** for a 'Local Culture Fair'. Try to get a diverse range of ideas.\n",
        "*   **Challenge**: You need to come up with a new product name for a sustainable, plant-based cleaning spray. Ask the LLM to suggest **15 creative and memorable names**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lyfO-GCFm5gT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Classification\n",
        "\n",
        "*   **Challenge**: Classify the sentiment of the following sentences as `positive`, `negative`, or `neutral`:\n",
        "    *   \"The new update to the software is incredibly buggy and crashes constantly.\"\n",
        "    *   \"I found the customer service to be very helpful and resolved my issue quickly.\"\n",
        "    *   \"The weather forecast predicts partly cloudy skies for tomorrow.\"\n",
        "    *   \"This coffee tastes like burnt rubber.\"\n",
        "    *   \"I really enjoyed learning about LLMs today.\"\n",
        "*   **Challenge**: Imagine you are sorting customer support tickets. Use the LLM to classify the following issues into categories like `Technical Support`, `Billing Inquiry`, `Feature Request`, or `General Question`:\n",
        "    *   \"My internet connection keeps dropping every few minutes.\"\n",
        "    *   \"Can you tell me how much my last bill was and if I can get an itemized statement?\"\n",
        "    *   \"It would be great if your app had a dark mode option.\"\n",
        "    *   \"I forgot my password and can't log in.\"\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MFR7yqeFn5wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Closed QA\n",
        "\n",
        "*   **Challenge**: Ask the LLM for the capital city of three different countries you are interested in (e.g., \"What is the capital of Japan?\").\n",
        "*   **Challenge**: In which year was the first iPhone released? (Ask the LLM this question).\n",
        "*   **Challenge**: What is the chemical symbol for gold?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "csYDtvrqn6m0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Generation\n",
        "\n",
        "*   **Challenge**: Write a short, creative paragraph describing a futuristic city powered entirely by renewable energy.\n",
        "*   **Challenge**: Generate a simple, two-verse poem about the ocean.\n",
        "*   **Challenge**: Create a short, encouraging message to someone starting a new job.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DWp_mefan7tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5: Information Extraction\n",
        "\n",
        "*   **Challenge**: Extract all the `dates` and `amounts` from the following paragraph: \"Our project started on January 15, 2023, with an initial budget of 50,000. We spent 12,500 in February and another 18,000 in March, with a final payment of 5,000 due on April 30, 2023.\"\n",
        "*   **Challenge**: From the text \"Attendees for the conference include Dr. Emily Carter from Tech Solutions, Mr. John Doe representing Global Innovations, and Ms. Sarah Lee, an independent researcher,\" extract the `names` and their `affiliations`.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "a8xoVKqGn9Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6: Open QA\n",
        "\n",
        "*   **Challenge**: Explain the concept of `machine learning` in simple terms for a non-technical audience.\n",
        "*   **Challenge**: What are some of the ethical considerations surrounding the development and deployment of `artificial intelligence`?\n",
        "*   **Challenge**: Describe the process of `photosynthesis`.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IHVn1vUan-Go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 7: Summarization\n",
        "\n",
        "*   **Challenge**: Summarize the following text in exactly two sentences: \"Artificial intelligence (AI) is a rapidly expanding field dedicated to creating machines that can think, learn, and act like humans. Its applications range from natural language processing and computer vision to robotics and autonomous vehicles. While AI offers immense potential for advancements in various sectors, it also presents challenges concerning ethics, privacy, and job displacement. Research continues to evolve, pushing the boundaries of what intelligent machines can achieve.\"\n",
        "*   **Challenge**: Provide a one-paragraph summary of a news article of your choice (copy and paste the article content into your prompt).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2cn6hUFVoaYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tasks 1-7 Individual Challenges\n",
        "\n",
        "multi_tasks = {\n",
        "    \"Brainstorming\": \"Suggest 15 creative names for a sustainable plant-based cleaning spray.\",\n",
        "    \"Classification\": \"Classify as Technical, Billing, or Feature Request: 'My internet drops every few minutes.'\",\n",
        "    \"Closed QA\": \"What is the chemical symbol for gold?\",\n",
        "    \"Generation\": \"Write a two-verse poem about the ocean.\",\n",
        "    \"Information Extraction\": \"Extract names and affiliations: 'Dr. Emily Carter from Tech Solutions and Mr. John Doe from Global Innovations.'\",\n",
        "    \"Open QA\": \"Explain machine learning in simple terms for a non-technical audience.\",\n",
        "    \"Summarization\": \"Summarize the BBC report on the John Logie Baird TV centennial and AI deepfakes.\"\n",
        "}\n",
        "\n",
        "# Execution Loop\n",
        "for name, prompt in multi_tasks.items():\n",
        "    response = client.responses.create(\n",
        "      model=model,\n",
        "      input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a multitask model.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(response.output_text)\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58cOOm7Un2oU",
        "outputId": "5ce60e60-425b-4bf6-c6a6-482eaecec9f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Brainstorming ---\n",
            "Sure! Here are 15 creative names for a sustainable plant-based cleaning spray:\n",
            "\n",
            "1. **EcoSparkle**\n",
            "2. **Green Gleam**\n",
            "3. **Nature's Clean**\n",
            "4. **Pure Plant Power**\n",
            "5. **Earthy Fresh**\n",
            "6. **Botanical Bliss**\n",
            "7. **Cleansing Essence**\n",
            "8. **Sprout & Shine**\n",
            "9. **Vital Vine Cleaner**\n",
            "10. **EcoEssence Spray**\n",
            "11. **Verdant Glow**\n",
            "12. **Leafy Luster**\n",
            "13. **Sustainable Suds**\n",
            "14. **Flora Fresh**\n",
            "15. **Nature's Touch**\n",
            "\n",
            "Feel free to mix and match or modify any of these!\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Classification ---\n",
            "This would be classified as **Technical**.\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Closed QA ---\n",
            "The chemical symbol for gold is **Au**.\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Generation ---\n",
            "In twilight's glow, the ocean sighs,  \n",
            "With whispers soft beneath the skies,  \n",
            "Waves dance and shimmer, a silver lace,  \n",
            "A timeless hymn, a boundless space.  \n",
            "\n",
            "Beneath the tide, where secrets dwell,  \n",
            "In coral realms, the stories swell,  \n",
            "A vast embrace, both fierce and calm,  \n",
            "The ocean's heart, a soothing balm.  \n",
            "\n",
            "========================================\n",
            "\n",
            "--- Information Extraction ---\n",
            "- Dr. Emily Carter, Tech Solutions\n",
            "- Mr. John Doe, Global Innovations\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Open QA ---\n",
            "Sure! Think of machine learning like teaching a computer to learn from experience, similar to how humans learn from examples.\n",
            "\n",
            "Imagine you have a pet dog. When you show it how to sit by giving it treats every time it gets it right, the dog eventually learns to sit on command. Machine learning works in a similar way.\n",
            "\n",
            "1. **Data as Examples**: In machine learning, we give the computer lots of examples (data). For instance, if we want it to recognize pictures of cats, we show it many pictures of cats and non-cats.\n",
            "\n",
            "2. **Learning Patterns**: The computer analyzes these examples to find patterns. It learns that cats usually have pointy ears, whiskers, and certain colors.\n",
            "\n",
            "3. **Making Predictions**: Once the computer has learned, we can show it a new picture it hasn‚Äôt seen before, and it can decide whether it‚Äôs a cat or not based on what it learned from the examples.\n",
            "\n",
            "4. **Improvement Over Time**: Just like the dog gets better with practice, the more data we provide and the more feedback we give, the better the computer becomes at making accurate predictions or decisions.\n",
            "\n",
            "So, in simple terms, machine learning is about teaching computers to recognize patterns and make decisions based on examples, improving their accuracy over time!\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Summarization ---\n",
            "The BBC report on the John Logie Baird TV centennial celebrates the 100th anniversary of the invention of television by the Scottish inventor. It highlights Baird's pioneering work and his significant contributions to broadcasting. The report also discusses the implications of AI deepfakes, emphasizing the challenges they pose to media integrity and trust. As technology evolves, there is a growing concern about the authenticity of visual content, raising ethical questions about the use of deepfake technology in news and entertainment.\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination Challenge\n",
        "\n",
        "*   **Challenge**: Pick a product review (e.g., from an Amazon product page). First, use **Information Extraction** to get the product name and the reviewer's rating. Then, use **Classification** to determine the overall sentiment of the review (positive, negative, neutral). Finally, use **Summarization** to condense the review into a single sentence."
      ],
      "metadata": {
        "id": "BJNjBvf5obVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8 Combination Challenge\n",
        "\n",
        "multi_combination = \"\"\"\n",
        "From this review: 'The HydroFlask is great! 5 stars. But the lid leaks.'\n",
        "1. [Information Extraction]: Product name and rating.\n",
        "2. [Classification]: Overall sentiment.\n",
        "3. [Summarisation]: One-sentence summary.\n",
        "\"\"\"\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a versatile text processor.\"},\n",
        "    {\"role\": \"user\", \"content\": multi_combination},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(\"--- Combination Challenge Output ---\")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGXy2A6nobxP",
        "outputId": "37c8882d-8d5a-40f3-d65e-a10a404711b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combination Challenge Output ---\n",
            "1. **Product name**: HydroFlask; **Rating**: 5 stars.\n",
            "2. **Overall sentiment**: Positive, but with a critical note.\n",
            "3. **One-sentence summary**: The HydroFlask is highly rated, but the lid has a leaking issue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Combination Challenges\n",
        "\n",
        "Here are a few more complex challenges that combine multiple LLM capabilities:\n",
        "\n",
        "*   **Challenge 1: Event Planning Assistant (Brainstorming + Generation)**\n",
        "    *   **Task**: Ask the LLM to **brainstorm 5 unique themes** for a virtual team-building event. Then, for each theme, ask the LLM to **generate a short (3-5 sentence) invitation email** that incorporates details relevant to that theme."
      ],
      "metadata": {
        "id": "OU_JWHSj4SvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Challenge 1: Event Planning Assistant\n",
        "prompt_1 = \"\"\"\n",
        "1. [Brainstorming]: Suggest 5 unique themes for a virtual team-building event.\n",
        "2. [Generation]: For each theme, write a short (3-5 sentence) invitation email including theme-specific details.\n",
        "\"\"\"\n",
        "\n",
        "response_1 = client.responses.create(\n",
        "    model=model,\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a creative event planning assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_1},\n",
        "    ]\n",
        ")\n",
        "print(\"--- Challenge 1: Event Planning Assistant ---\\n\")\n",
        "print(response_1.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZz3gGwe4TLH",
        "outputId": "4ef8a797-5f93-4392-e50f-de2e8721b39d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Challenge 1: Event Planning Assistant ---\n",
            "\n",
            "### 1. Adventure Quest\n",
            "**Invitation Email:**\n",
            "\n",
            "Subject: Join Us for an Adventure Quest!\n",
            "\n",
            "Dear Team,\n",
            "\n",
            "Get ready for an exhilarating virtual team-building experience! Join us for our ‚ÄúAdventure Quest‚Äù event on [Date] at [Time]. Put on your thinking caps as we embark on a virtual treasure hunt filled with challenges and puzzles that will test your wits and promote teamwork. Prepare to explore both trivia and creative tasks, with prizes for the top adventurers! Don‚Äôt forget to dress for adventure!\n",
            "\n",
            "Best,  \n",
            "[Your Name]\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Around the World in One Hour\n",
            "**Invitation Email:**\n",
            "\n",
            "Subject: Embark on a Journey Around the World!\n",
            "\n",
            "Dear Team,\n",
            "\n",
            "Pack your virtual bags for our ‚ÄúAround the World in One Hour‚Äù event on [Date] at [Time]! Experience diverse cultures through fun activities, trivia, and mini-games based on different countries. Learn a few words in different languages and enjoy a quick cooking demonstration to whip up a traditional snack from one of the cultures featured! Join us for a global experience right from the comfort of your home.\n",
            "\n",
            "Cheers,  \n",
            "[Your Name]\n",
            "\n",
            "---\n",
            "\n",
            "### 3. Time Travelers' Gala\n",
            "**Invitation Email:**\n",
            "\n",
            "Subject: Step into the Time Travelers' Gala!\n",
            "\n",
            "Dear Team,\n",
            "\n",
            "Put on your time-traveling gear for our ‚ÄúTime Travelers' Gala‚Äù on [Date] at [Time]! We‚Äôll be jumping through different eras with themed games encompassing everything from the Roaring '20s to the Futuristic '30s. Dress up in your favorite era‚Äôs attire and prepare for a night of engaging trivia, fun facts, and team challenges that will take you on a journey through time. You won‚Äôt want to miss this unique experience!\n",
            "\n",
            "Best,  \n",
            "[Your Name]\n",
            "\n",
            "---\n",
            "\n",
            "### 4. DIY Science Fair\n",
            "**Invitation Email:**\n",
            "\n",
            "Subject: Get Ready for the DIY Science Fair!\n",
            "\n",
            "Hi Team,\n",
            "\n",
            "Join us for a ‚ÄúDIY Science Fair‚Äù on [Date] at [Time] where creativity meets experimentation! Each team will be challenged to create and present a simple science experiment using household items. Prepare to unleash your inner scientist and enjoy a fun mix of learning and laughter as we explore the wonders of science together. Prizes will be awarded for the most innovative and entertaining presentations!\n",
            "\n",
            "Excited,  \n",
            "[Your Name]\n",
            "\n",
            "---\n",
            "\n",
            "### 5. Mystery Masquerade\n",
            "**Invitation Email:**\n",
            "\n",
            "Subject: Unveil the Secrets at Our Mystery Masquerade!\n",
            "\n",
            "Dear Team,\n",
            "\n",
            "Get ready for intrigue and excitement at our ‚ÄúMystery Masquerade‚Äù event on [Date] at [Time]! Come dressed in your best masquerade attire, and prepare for an evening filled with mystery games and clever puzzles. Work in teams to solve a thrilling whodunit as we unravel the story together. Don‚Äôt miss out on this chance to showcase your sleuthing skills and enjoy some fun surprises!\n",
            "\n",
            "Best,  \n",
            "[Your Name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **Challenge 2: Research Summary & Analysis (Information Extraction + Summarization + Classification)**\n",
        "    *   **Task**: Find a scientific abstract or a short news article (at least 200 words) about a new technology or discovery. First, use **Information Extraction** to pull out the key entities (e.g., names of researchers, organizations, specific technologies, dates). Then, use **Summarization** to condense the entire text into a paragraph of 3-4 sentences. Finally, use **Classification** to determine if the overall sentiment of the article towards the technology/discovery is `positive`, `negative`, or `neutral`."
      ],
      "metadata": {
        "id": "_bByPnh_6Pr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Challenge 2: Research Summary & Analysis\n",
        "# Source text about Solid-State Battery discovery\n",
        "research_text = \"\"\"\n",
        "Researchers led by Dr. Arisaka at the Tokyo Institute of Technology announced on January 15, 2026,\n",
        "a breakthrough in solid-state battery technology. The new 'Neo-Ion' electrolyte allows for\n",
        "charging speeds five times faster than current lithium-ion batteries. While the manufacturing\n",
        "costs remain high, the discovery promises to revolutionize the electric vehicle market by 2030.\n",
        "\"\"\"\n",
        "\n",
        "prompt_2 = f\"\"\"\n",
        "From this text: '{research_text}'\n",
        "1. [Information Extraction]: Extract key entities (researchers, organizations, technologies, dates).\n",
        "2. [Summarization]: Condense the text into 3-4 sentences.\n",
        "3. [Classification]: Determine if the sentiment is positive, negative, or neutral.\n",
        "\"\"\"\n",
        "\n",
        "response_2 = client.responses.create(\n",
        "    model=model,\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a scientific research analyst.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_2},\n",
        "    ]\n",
        ")\n",
        "print(\"\\n--- Challenge 2: Research Summary & Analysis ---\\n\")\n",
        "print(response_2.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgNkjhyw545R",
        "outputId": "52e187b8-6f7d-49aa-9506-4056c853ef5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Challenge 2: Research Summary & Analysis ---\n",
            "\n",
            "### 1. Information Extraction\n",
            "- **Researchers**: Dr. Arisaka\n",
            "- **Organizations**: Tokyo Institute of Technology\n",
            "- **Technologies**: Neo-Ion electrolyte, solid-state battery technology\n",
            "- **Dates**: January 15, 2026, expected revolution by 2030\n",
            "\n",
            "### 2. Summarization\n",
            "On January 15, 2026, Dr. Arisaka and his team at the Tokyo Institute of Technology announced a significant advancement in solid-state battery technology with the new 'Neo-Ion' electrolyte. This innovation enables charging speeds five times faster than conventional lithium-ion batteries. Although manufacturing costs are currently high, this breakthrough has the potential to transform the electric vehicle market by 2030.\n",
            "\n",
            "### 3. Classification\n",
            "The sentiment is positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **Challenge 3: Product Feedback Processor (Classification + Information Extraction + Open QA)**\n",
        "    *   **Task**: Imagine you receive the following customer feedback: \"The new app update is terrible! It crashes every time I try to open it, and the new navigation is so confusing. I loved the old version, it was much faster and easier to use. Please fix this soon!\" First, use **Classification** to determine the overall sentiment. Then, use **Information Extraction** to identify specific pain points or features mentioned (e.g., 'crashing', 'confusing navigation', 'faster', 'easier'). Finally, use **Open QA** to ask the LLM to suggest `3 potential solutions or improvements` based on the extracted pain points."
      ],
      "metadata": {
        "id": "Yw62W_rv6Wih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Challenge 3: Product Feedback Processor\n",
        "feedback_text = \"The new app update is terrible! It crashes every time I try to open it, and the new navigation is so confusing. I loved the old version, it was much faster and easier to use. Please fix this soon!\"\n",
        "\n",
        "prompt_3 = f\"\"\"\n",
        "From this feedback: '{feedback_text}'\n",
        "1. [Classification]: Determine the overall sentiment.\n",
        "2. [Information Extraction]: Identify specific pain points or features mentioned.\n",
        "3. [Open QA]: Suggest 3 potential solutions or improvements to address these issues.\n",
        "\"\"\"\n",
        "\n",
        "response_3 = client.responses.create(\n",
        "    model=model,\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a customer experience specialist.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_3},\n",
        "    ]\n",
        ")\n",
        "print(\"\\n--- Challenge 3: Product Feedback Processor ---\\n\")\n",
        "print(response_3.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXqU9JRX55Vv",
        "outputId": "3b7ee0bf-02ce-48b4-a976-351f6db99c3a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Challenge 3: Product Feedback Processor ---\n",
            "\n",
            "1. **[Classification]**: The overall sentiment is negative.\n",
            "\n",
            "2. **[Information Extraction]**: \n",
            "   - **Pain points**:\n",
            "     - App crashes when trying to open it.\n",
            "     - New navigation is confusing.\n",
            "   - **Features mentioned**:\n",
            "     - User preference for the old version, which was faster and easier to use.\n",
            "\n",
            "3. **[Open QA]**: \n",
            "   - **Potential Solutions**:\n",
            "     1. **Bug Fix and Updates**: Release a patch to address the crashing issue, ensuring users can open the app without problems. Communicate the update clearly to users.\n",
            "     2. **User Interface (UI) Redesign**: Simplify the new navigation based on user feedback. Consider implementing a tutorial or guide to help users adapt to the new layout.\n",
            "     3. **Roll Back Option**: Provide a temporary option to revert back to the previous version of the app for users who prefer it while addressing the current issues. This could help retain user satisfaction in the interim.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **Challenge 4: Creative Story Spark (Brainstorming + Generation + Closed QA)**\n",
        "    *   **Task**: Ask the LLM to **brainstorm 3 unusual plot twists** for a fantasy story. Pick one. Then, use **Closed QA** to ask the LLM for `a single unique magical artifact` that would fit into a story with that chosen plot twist. Finally, use **Generation** to write `a short paragraph (5-7 sentences)` that incorporates the chosen plot twist and the magical artifact into the beginning of a story.\n",
        "\n",
        "These challenges require more thought in structuring the prompts and chaining the outputs, providing a deeper understanding of practical LLM applications!"
      ],
      "metadata": {
        "id": "-xm30Mz26ZbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Challenge 4: Creative Story Spark\n",
        "prompt_4 = \"\"\"\n",
        "1. [Brainstorming]: Suggest 3 unusual plot twists for a fantasy story.\n",
        "2. [Closed QA]: Choose the best twist and name a single unique magical artifact that fits it.\n",
        "3. [Generation]: Write a 5-7 sentence paragraph starting a story that incorporates that twist and artifact.\n",
        "\"\"\"\n",
        "\n",
        "response_4 = client.responses.create(\n",
        "    model=model,\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a creative writing assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_4},\n",
        "    ]\n",
        ")\n",
        "print(\"\\n--- Challenge 4: Creative Story Spark ---\\n\")\n",
        "print(response_4.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHPst9Zd55yC",
        "outputId": "045d2ada-a0af-41e1-d5d0-1bc1be0edc2c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Challenge 4: Creative Story Spark ---\n",
            "\n",
            "### 1. Unusual Plot Twists for a Fantasy Story:\n",
            "- **The Betrayer is a Visionary**: A character who seems to be betraying the hero is actually receiving prophetic visions of the future where their actions prevent a disastrous outcome. They are misunderstood and vilified until the truth is revealed.\n",
            "- **The Chosen One is a Decoy**: The prophesied hero turns out to be a mere decoy, created by a hidden order to distract from the real chosen one, who has been living in obscurity all along.\n",
            "- **The Cursed Object Grants Foresight**: An artifact believed to bring misfortune instead allows the user to peer into potential futures, showing them choices that lead to doom or salvation, but at a steep emotional cost.\n",
            "\n",
            "### 2. Best Twist and Magical Artifact:\n",
            "**Best Twist**: The Betrayer is a Visionary  \n",
            "**Magical Artifact**: The Eye of Trelis  \n",
            "\n",
            "### 3. Story Start Paragraph:\n",
            "In the quiet village of Eldergrove, shadows lingered longer than they should, clinging to the cobblestones like remnants of lost hopes. Amara gripped the Eye of Trelis tightly in her hand, its blood-red gem pulsing softly with each heartbeat‚Äîa curse and a blessing intertwined. She had long since accepted her role as the villager's outcast, her glimpses into the future branded her a traitor, yet they were the only thing standing between them and impending doom. Each vision she received sent shivers down her spine; she had watched her friend Elian fall to darkness as the prophecy twisted in ways mere mortals could not comprehend. But to act was to risk everything, including the love she hid beneath her torn leather armor. As she peered through the Eye again, she realized with a jolt that the next vision held a choice‚Äîone that could save them all or shatter the fragile threads of trust forever.\n"
          ]
        }
      ]
    }
  ]
}